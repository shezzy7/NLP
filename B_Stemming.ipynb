{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Stemming***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming is a process in Natural Language Processing (NLP) that reduces a word to its root or base form by removing suffixes and prefixes.\n",
    "\n",
    "For example:\n",
    "\n",
    "\"running\" → \"run\"\n",
    "\"played\" → \"play\"\n",
    "\"happily\" → \"happi\" (sometimes not a real word)\n",
    "The goal of stemming is to make different versions of a word look the same so computers can process text more efficiently.\n",
    "For this purpose we nltk provides us built-in methods to make stemming of words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***First of all for using stem in our code we need to import PorterStemmer from nltk.stem which is basically a method that takes words and returns them after stemming.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we calling PorterStemmer function and saving it in a variable.This function's output contains a stem method with the help of which we apply stemming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sing = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "plurals = ['caresses', 'flies', 'dies', 'mules', 'denied',\n",
    "        'died', 'agreed', 'owned', 'humbled', 'sized',\n",
    "        'meeting', 'stating', 'siezing', 'itemization',\n",
    "        'sensational', 'traditional', 'reference', 'colonizer',\n",
    "        'plotted']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can't pass list of words to stemmer method as a whole.Instead we pass words individually.\n",
    "So here if we want to apply stemming over all the words of this list then we should access each words through a loop and apply stemming individually on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caresses--->caress\n",
      "flies--->fli\n",
      "dies--->die\n",
      "mules--->mule\n",
      "denied--->deni\n",
      "died--->die\n",
      "agreed--->agre\n",
      "owned--->own\n",
      "humbled--->humbl\n",
      "sized--->size\n",
      "meeting--->meet\n",
      "stating--->state\n",
      "siezing--->siez\n",
      "itemization--->item\n",
      "sensational--->sensat\n",
      "traditional--->tradit\n",
      "reference--->refer\n",
      "colonizer--->colon\n",
      "plotted--->plot\n"
     ]
    }
   ],
   "source": [
    "for word in plurals:\n",
    "    print(word+\"--->\"+sing.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***RegexpStemmer***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import RegexpStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if we to documentation then we will see that RegexpStemmer takes two arguments as input one the regular expressions that we want to remove from words and other is min length of those expression\n",
    "\n",
    "reges = RegexpStemmer(\"ing$|s$|ed$|able$\",min=4)#here only those words suffix will be removed who have any if these words as there suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'play'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reges.stem(\"playing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'li'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reges.stem(\"liable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'played'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reges.stem(\"playeding\")#played"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ingplay'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reges.stem(\"ingplay\")#will remain same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***SnowballStemmer***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SnowballStemmer is used for stemming and it works like PorterStemmer.But it is more effiecient as compared other stemming methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#snowballStemmer takes an argument language\n",
    "snowStem = SnowballStemmer(language=\"english\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now lets use it and make a compsrison of it with porterStemmer on the same words.WE will see that snowballstemmer will be giving best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fair'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowStem.stem(\"fairly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fairli'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sing.stem(\"fairly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "but in some cases snowballStemmer also gives bad results.So for making  our results perfect we use concept of lammatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('goe', 'goe')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Here we will see that both will stem with same result which is not correct\n",
    "sing.stem(\"goes\"),snowStem.stem(\"goes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So to overcome this problem we use lemmatization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
